{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "client = tweepy.Client('<BearerToken>')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_by_userID_list(users_id):\n",
    "    \n",
    "    dictionary = {}\n",
    "    for i in users_id:\n",
    "        tweetlist =[]\n",
    "        usertweet = client.get_users_tweets(id=i,max_results=100)\n",
    "        for tweet in usertweet.data:\n",
    "            tweetlist.append(tweet.text)\n",
    "        dictionary[i] = tweetlist\n",
    "    return(dictionary)\n",
    "\n",
    "print(get_tweets_by_userID_list(['487297085']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tweets by one Obama account\n",
    "def check_if_active_and_valid(user_id: str):\n",
    "    \"\"\"This functions returns False if the user has not been active since October 1 of 2022,\n",
    "    True otherwise.  It should also return false for bad (not numeric) IDs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        check = client.get_users_tweets(id=user_id,max_results=10, start_time='2022-10-01T00:00:00Z')\n",
    "    except:\n",
    "        return False\n",
    "    return (not check.data is None)\n",
    "\n",
    "print(get_tweets_by_userID_list(['216776631', '29442313']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function does not work yet\n",
    "\n",
    "def pol_data_cleaner_by_last_active(df):\n",
    "    \"\"\"This function will take a data frame representing twitter\n",
    "    users, and will take out anyone that has not been active\n",
    "    since Oct 1 2022.\n",
    "    \"\"\"\n",
    "    df = df.dropna(how='any',axis=0) \n",
    "    ID_list = list(df['Account_ID'])\n",
    "    ID_list_str = [str(x) for x in ID_list]\n",
    "    df['Active'] = [check_if_active_and_valid(x) for x in ID_list_str]\n",
    "    clean_df = df[df['Active'] == True]\n",
    "    clean_df = clean_df.drop(['Active'], axis=1)\n",
    "    return clean_df\n",
    "\n",
    "data = pd.read_csv('cleaner_politicians.csv')\n",
    "clean = pol_data_cleaner_by_last_active(data)\n",
    "print(clean)\n",
    "clean.to_csv('cleanest_politicians.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirm_its_clean(df):\n",
    "    from collections import Counter\n",
    "    \"\"\"Checks that there are no duplcates IDs\n",
    "    or name in our csv.\"\"\"\n",
    "    name_list = list(df['Name'])\n",
    "    return Counter(name_list)\n",
    "\n",
    "print(confirm_its_clean(pd.read_csv('cleanest_politicians.csv')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from cleantext import clean\n",
    "def twitter(users_id):\n",
    "    \"\"\"Script for gathering raw tweets for a list of user id\"\"\"\n",
    "    dictionary = {}\n",
    "    for i in users_id:\n",
    "        tweetlist =[]\n",
    "        usertweet = client.get_users_tweets(id=i,max_results=10)\n",
    "        for tweet in usertweet.data:\n",
    "            #get rid of emoji\n",
    "            cleantext = clean(str(tweet.text))\n",
    "            # remove tab\n",
    "            text = cleantext.replace('\\n',' ')\n",
    "            # get rid of url/links\n",
    "            rawtwt = re.sub(r'https?:\\/\\/\\S*', '', text, flags=re.MULTILINE)\n",
    "            #append raw tweet\n",
    "            tweetlist.append(rawtwt)\n",
    "        dictionary[i] = tweetlist\n",
    "    return(dictionary)\n",
    "\n",
    "print(twitter(['216776631']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paginator testing\n",
    "\n",
    "counter = 0\n",
    "for tweet in tweepy.Paginator(client.get_users_tweets, \"216776631\",\n",
    "                                max_results=10).flatten(limit=10):\n",
    "    print(tweet.id)\n",
    "    counter += 1\n",
    "\n",
    "print(counter)\n",
    "\n",
    "#It works, we can get a lot more tweets per user this way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get tweets with pagination, put them into a csv\n",
    "\n",
    "import re\n",
    "from cleantext import clean\n",
    "def get_paged_tweets(user_id):\n",
    "    \"\"\"Script for gathering raw tweets for a list of user id and saving them to csv\"\"\"\n",
    "    df = pd.DataFrame(columns=['TweetID', 'UserID', 'Text'])\n",
    "    tweetlist =[]\n",
    "        # usertweet_page = tweepy.Paginator(client.get_users_tweets, i,\n",
    "                                # max_results=10).flatten(limit=10)\n",
    "        # print(usertweet_page.id)\n",
    "    for tweet in tweepy.Paginator(client.get_users_tweets, user_id, exclude='retweets',\n",
    "                                  max_results=100).flatten(limit=1000):\n",
    "        #     #get rid of emoji\n",
    "        # tweet_text = tweet.text.lower()\n",
    "        # clean_text = clean(str(tweet_text))\n",
    "        #     # remove tab\n",
    "        text = tweet.text.replace('\\n',' ')\n",
    "        # print(text)\n",
    "        #     # get rid of url/links\n",
    "        # rawtwt = re.sub(r'https?:\\/\\/\\S*', '', text, flags=re.MULTILINE)\n",
    "        #     #append raw tweet\n",
    "        df.loc[len(df.index)] = [tweet.id, user_id, text]\n",
    "    return df\n",
    "\n",
    "print(get_paged_tweets('487297085'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct csvs for each politician\n",
    "from pathlib import Path\n",
    "\n",
    "def fetch_tweets(ID_list, name_list):\n",
    "    \n",
    "    # df = pd.read_csv('cleanest_politicians.csv')\n",
    "    # ID_list = list(df['Account_ID'])\n",
    "    # name_list = list(df['Name'])\n",
    "\n",
    "        \n",
    "    for i in range(0, len(ID_list)):\n",
    "        file = Path('/Users/dustinhayes/Desktop/STAT766Final/fixed_pol_csvs/{}-{}.csv'.format((ID_list[i]), name_list[i]))\n",
    "        print('getting {}'.format(name_list[i]))\n",
    "        if file.exists():\n",
    "            pass\n",
    "        else:\n",
    "            df = get_paged_tweets(ID_list[i])\n",
    "            df.to_csv('/Users/dustinhayes/Desktop/STAT766Final/fixed_pol_csvs/{}-{}.csv'.format((ID_list[i]), name_list[i]))\n",
    "\n",
    "fetch_tweets(['80013913', '256074273', '487297085', '854715071116849157', '233737858'], ['Ricardo Rossello', 'Roland Gtierrez', 'Ron DeSantis', 'Ron Estes', 'Ron John'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter csvs such that only pol with X or more tweets included\n",
    "\n",
    "def make_pol_csvs_min_only(csv_path: str, min_tweets: int):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if len(list(df['TweetID'])) >= min_tweets:\n",
    "        df.to_csv('{}\\\\{}'.format(min_tweets))\n",
    "        print(csv_path)\n",
    "\n",
    "os.chdir('/Users/dustinhayes/Desktop/STAT766Final/politician_csvs')\n",
    "pol_csvs = os.listdir()\n",
    "for i in range(0, len(pol_csvs[0:5])):\n",
    "    make_pol_csvs_min_only(pol_csvs[i], 1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
